version: '2'
services:

  api:
    build:
      context: .
    extra_hosts:
      - "host.docker.internal:host-gateway"
    ports:
      - "8000:8000"
    volumes:
      - .:/app
    entrypoint: dockerize -wait tcp://postgres:5432 -wait tcp://mi-postgres:5432 -wait tcp://es:9200 -wait tcp://es-apm:8200 -wait tcp://redis:6379 -timeout 120s
    env_file: .env
    depends_on:
      - postgres
      - mi-postgres
      - es
      - redis
      - celery
      - es-apm
    command: /app/start.sh

  celery:
    build:
      context: .
    volumes:
      - .:/app
    entrypoint: dockerize -wait tcp://postgres:5432 -wait tcp://mi-postgres:5432 -wait tcp://es:9200 -wait tcp://es-apm:8200 -wait tcp://redis:6379 -timeout 180s
    env_file: .env
    command: watchmedo auto-restart -d . -R -p '*.py' -- celery worker -A config -l info -Q celery -B

  postgres:
    image: postgres:10
    restart: always
    environment:
      - POSTGRES_DB=datahub
      - POSTGRES_PASSWORD=datahub

  mi-postgres:
    image: postgres:9.6
    restart: always
    environment:
      - POSTGRES_DB=mi
      - POSTGRES_PASSWORD=mi

  es:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.10.0
    environment:
      - discovery.type=single-node
      - http.port=9200
    restart: always
    ports:
      - "9200:9200"

  es-apm:
    image: docker.elastic.co/apm/apm-server:7.7.1
    restart: always
    ports:
      - "8200:8200"
    command: >
       apm-server -e
         -E output.elasticsearch.hosts=["es:9200"]
    depends_on:
      - es

  redis:
    image: redis:3.2
    restart: always
    ports:
      - "6379:6379"
