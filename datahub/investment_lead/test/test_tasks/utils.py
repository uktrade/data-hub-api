import gzip
import json

import boto3

from moto import mock_aws

from datahub.investment_lead.tasks.ingest_eyb_common import REGION
from datahub.investment_lead.test.factories import (
    eyb_lead_marketing_record_faker,
    eyb_lead_triage_record_faker,
    eyb_lead_user_record_faker,
)


@mock_aws
def setup_s3_client():
    return boto3.client('s3', REGION)


def file_contents_faker(records: list[dict] = None, default_faker: str = 'triage') -> bytes:
    """Create fake file contents with the specified list of records.

    Returns compressed lines of JSON encoded with UTF-8.

    If no records are provided, it creates a file with a single record,
    randomly generated by the default_faker.
    """
    if not records:
        if default_faker == 'triage':
            records = [eyb_lead_triage_record_faker()]
        elif default_faker == 'user':
            records = [eyb_lead_user_record_faker()]
        elif default_faker == 'marketing':
            records = [eyb_lead_marketing_record_faker()]
    json_lines = [
        json.dumps({'object': record}, default=str)
        for record in records
    ]
    compressed_content = gzip.compress('\n'.join(json_lines).encode('utf-8'))
    return compressed_content


@mock_aws
def setup_s3_bucket(bucket_name, test_file_paths, test_file_contents=None):
    """Sets up a mocked S3 bucket.

    The list of file paths and file contents should be the same length.
    If test_file_contents is None, a list of strings is used.
    """
    mock_s3_client = boto3.client('s3', REGION)
    mock_s3_client.create_bucket(
        Bucket=bucket_name,
        CreateBucketConfiguration={'LocationConstraint': REGION},
    )
    if test_file_contents is None:
        test_file_contents = [f'Test content {i}' for i in test_file_paths]
    for file_path, file_contents in zip(test_file_paths, test_file_contents):
        mock_s3_client.put_object(Bucket=bucket_name, Key=file_path, Body=file_contents)
