# Generate large data set for testing
The below instructions explain how you can quickly generate a large data set for testing purposes.

Start by running the below script from a python shell (`python ./manage.py shell`) on either your local or docker instance. You can set how many advisers/companies are generated by altering the value of the call to `advisers = AdviserFactory.create_batch(1800)`

The script creates Advisers and Companies without synchronising these with Open Search to speed up the process. Once the script has completed update the Open Search index (see below)

## Generator script
````
from datetime import timedelta
from random import random
from pprint import pprint
import time
from django.db.models.signals import (
    post_delete,
    post_init,
    post_migrate,
    post_save,
    pre_delete,
    pre_init,
    pre_migrate,
    pre_save,
)

from datahub.company.test.factories import (
    AdviserFactory,
    ArchivedCompanyFactory,
    CompanyFactory,
    CompanyWithAreaFactory,
    OneListCoreTeamMemberFactory,
    SubsidiaryFactory,
)
from collections import defaultdict
from django.db.models.signals import *
import random

class DisableSignals(object):
    def __init__(self, disabled_signals=None):
        self.stashed_signals = defaultdict(list)
        self.disabled_signals = disabled_signals or [
            pre_init, post_init,
            pre_save, post_save,
            pre_delete, post_delete,
            pre_migrate, post_migrate, m2m_changed,
        ]

    def __enter__(self):
        for signal in self.disabled_signals:
            self.disconnect(signal)

    def __exit__(self, exc_type, exc_val, exc_tb):
        for signal in list(self.stashed_signals):
            self.reconnect(signal)

    def disconnect(self, signal):
        self.stashed_signals[signal] = signal.receivers
        signal.receivers = []

    def reconnect(self, signal):
        signal.receivers = self.stashed_signals.get(signal, [])
        del self.stashed_signals[signal]

# Disable open search indexing
with DisableSignals():
    start_time = time.time()

    # In February 2024 there where 18,000 advisers and 500,000 companies.
    # Alter number of adivsers below to create larger or smaller data set.
    advisers = AdviserFactory.create_batch(1800)
    print(f'Generated {len(advisers)} advisers')
    for index, adviser in enumerate(advisers):
        CompanyFactory.create_batch(random.randint(1, 25), created_by=adviser, modified_by=adviser)
        
        # The ratios of the below types of companies do not reflect the live database.
        SubsidiaryFactory.create_batch(random.randint(1, 5), created_by=adviser, modified_by=adviser)
        CompanyWithAreaFactory.create_batch(random.randint(0, 1), created_by=adviser, modified_by=adviser)
        ArchivedCompanyFactory.create_batch(random.randint(0, 1), created_by=adviser, modified_by=adviser)
        # Show a sign of live every now and then
        if index % 10 == 0 : print(".", end='')

    print()
    elapsed = time.time() - start_time
    print(str(f"{timedelta(seconds=elapsed)}"))
````

# Update open search
From your command line (either local or docker instance) start the open search synchronisation by running:

`python manage.py sync_search`

You should be able to see its progress by monitoring the rq_long and rq_short.